{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Importamos las librer√≠as necesarias :***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "from pathlib import Path\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from torch.utils.data import DataLoader, TensorDataset, Subset\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Guardamos las trayectorias con sus respectivas clases en \"complete_df\" :***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "csv_files = [\n",
    "    \"./Trayectorias/Tipos_de_barcos/longitud_8/Cargo_modificado_compressed_8.csv\",\n",
    "    \"./Trayectorias/Tipos_de_barcos/longitud_8/Container_modificado_compressed_8.csv\",\n",
    "    \"./Trayectorias/Tipos_de_barcos/longitud_8/Cruise_modificado_compressed_8.csv\",\n",
    "    \"./Trayectorias/Tipos_de_barcos/longitud_8/Fishing_modificado_compressed_8.csv\",\n",
    "    \"./Trayectorias/Tipos_de_barcos/longitud_8/Tanker_modificado_compressed_8.csv\"\n",
    "]\n",
    "\"\"\"\n",
    "csv_files = [\n",
    "    \"./Trayectorias/Tipos_de_barcos/longitud_8/Cargo_modificado_compressed_8_v2.csv\",\n",
    "    \"./Trayectorias/Tipos_de_barcos/longitud_8/Container_modificado_compressed_8_v2.csv\",\n",
    "    \"./Trayectorias/Tipos_de_barcos/longitud_8/Tanker_modificado_compressed_8_v2.csv\"\n",
    "]\n",
    "\n",
    "complete_df = pd.DataFrame()\n",
    "\n",
    "for file in csv_files:\n",
    "    df = pd.read_csv(file)\n",
    "    df['Bearing'] = df['Bearing'].round(4)\n",
    "    grouped = df.groupby('Trajectory_ID')['Bearing'].apply(lambda x: [i for i in x if pd.notna(i)]).reset_index()\n",
    "    grouped['Type'] = file.split('/')[-1].split('_')[0]\n",
    "    complete_df = pd.concat([complete_df, grouped], ignore_index=True)\n",
    "\n",
    "### COMPROBACI√ìN BEARING ###\n",
    "for tipo in complete_df['Type'].unique():\n",
    "    first_element = complete_df[complete_df['Type'] == tipo].iloc[0]\n",
    "    print(f\"Type: {tipo}, Trajectory_ID: {first_element['Trajectory_ID']}, Bearing: {first_element['Bearing']}\")\n",
    "\n",
    "print()\n",
    "\n",
    "### COMPROBACI√ìN N√öMERO DE TRAYECTORIAS ###\n",
    "print(\"N√∫mero total de trayectorias:\", len(complete_df))\n",
    "class_counts = complete_df['Type'].value_counts()\n",
    "print(class_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Dividimos \"complete_df\" en entrenamiento y test :***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_df = complete_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "test_size = 0.2\n",
    "train_df_list = []\n",
    "test_df_list = []\n",
    "\n",
    "classes = complete_df['Type'].unique()\n",
    "\n",
    "for class_name in classes:\n",
    "    class_subset = complete_df[complete_df['Type'] == class_name]\n",
    "    \n",
    "    test_count = int(len(class_subset) * test_size)\n",
    "    \n",
    "    test_df_list.append(class_subset.iloc[:test_count])\n",
    "    train_df_list.append(class_subset.iloc[test_count:])\n",
    "\n",
    "train_df = pd.concat(train_df_list).reset_index(drop=True)\n",
    "test_df = pd.concat(test_df_list).reset_index(drop=True)\n",
    "\n",
    "train_df = train_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "test_df = test_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "#### COMPROBACI√ìN ####\n",
    "print(f\"N¬∫ de trayectorias en train: {len(train_df)}\")\n",
    "print(train_df['Type'].value_counts())\n",
    "print()\n",
    "print(f\"N¬∫ de trayectorias en test: {len(test_df)}\")\n",
    "print(test_df['Type'].value_counts())\n",
    "print()\n",
    "print(\"Ejm. conjunto train:\")\n",
    "print(train_df.head(5))\n",
    "print()\n",
    "print(\"Ejm. conjunto test:\")\n",
    "print(test_df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Pre-procesado de los datos :***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convertimos Bearing a un array de numpy\n",
    "X_train = np.array(train_df['Bearing'].tolist())\n",
    "X_test = np.array(test_df['Bearing'].tolist())\n",
    "\n",
    "#Normalizamos los valores de Bearing\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "#A√±adimos una dimensi√≥n extra para que tenga la forma (n, 1)\n",
    "X_train = np.expand_dims(X_train, axis = -1)\n",
    "X_test = np.expand_dims(X_test, axis = -1)\n",
    "\n",
    "#Codificamos las etiquetas de Type\n",
    "label_encoder = LabelEncoder()\n",
    "y_train = label_encoder.fit_transform(train_df['Type'])\n",
    "y_test = label_encoder.transform(test_df['Type'])\n",
    "\n",
    "#Conversi√≥n a tensores\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32).permute(0, 2, 1).to(device)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32).permute(0, 2, 1).to(device)\n",
    "y_train = torch.tensor(y_train, dtype=torch.long).to(device)\n",
    "y_test = torch.tensor(y_test, dtype=torch.long).to(device)\n",
    "\n",
    "print(\"X_train:\", X_train.shape, X_train.device)\n",
    "print(\"y_train:\", y_train.shape, y_train.device)\n",
    "print(\"X_test:\", X_test.shape, X_test.device)\n",
    "print(\"y_test:\", y_test.shape, y_test.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***CNN1D :***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN1D(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CNN1D, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2)\n",
    "        self.conv2 = nn.Conv1d(32, 64, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(64 * (X_train.shape[2] // 4), 128)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Configuraci√≥n del modelo :***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_folds = 5\n",
    "batch_size = 32\n",
    "num_epochs = 100\n",
    "num_classes = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Entrenamiento del modelo :***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "kfold = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "\n",
    "fold_train_acc = []\n",
    "fold_train_loss = []\n",
    "fold_val_acc = []\n",
    "fold_val_loss = []\n",
    "\n",
    "best_val_acc = 0\n",
    "best_epoch_train_acc = []\n",
    "best_epoch_val_acc = []\n",
    "best_epoch_train_loss = []\n",
    "best_epoch_val_loss = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kfold.split(train_dataset)):\n",
    "\n",
    "    epoch_train_acc = []\n",
    "    epoch_val_acc = []\n",
    "    epoch_train_loss = []\n",
    "    epoch_val_loss = []\n",
    "\n",
    "    print(f\"\\nüìÇ Fold {fold+1}/{k_folds}\")\n",
    "\n",
    "    train_subset = Subset(train_dataset, train_idx)\n",
    "    val_subset = Subset(train_dataset, val_idx)\n",
    "\n",
    "    train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    model = CNN1D(num_classes=num_classes).to(device)\n",
    "\n",
    "    #Pesos inversamente proporcionales a la frecuencia de las clases\n",
    "    label_counts = Counter(y_train.cpu().numpy())\n",
    "    total_count = sum(label_counts.values())\n",
    "    weights = [total_count / (num_classes * label_counts[label]) for label in range(len(label_counts))]\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss(weight=torch.tensor(weights).to(device))\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        correct_train = 0\n",
    "        total_train = 0\n",
    "\n",
    "        for inputs, labels in tqdm(train_loader, desc=f\"Fold {fold+1} | Epoch {epoch+1}/{num_epochs}\"):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct_train += (predicted == labels).sum().item()\n",
    "            total_train += labels.size(0)\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        train_acc = 100 * correct_train / total_train\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        correct_val = 0\n",
    "        total_val = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                correct_val += (predicted == labels).sum().item()\n",
    "                total_val += labels.size(0)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        val_acc = 100 * correct_val / total_val\n",
    "\n",
    "        epoch_train_acc.append(train_acc)\n",
    "        epoch_val_acc.append(val_acc)\n",
    "        epoch_train_loss.append(avg_train_loss)\n",
    "        epoch_val_loss.append(avg_val_loss)\n",
    "\n",
    "        print(f\"Fold {fold+1} - Epoch {epoch+1} ‚úÖ | Train Acc: {train_acc:.2f}% - Train Loss: {avg_train_loss:.4f} | Val Acc: {val_acc:.2f}% - Val Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "    fold_train_acc.append(train_acc)\n",
    "    fold_val_acc.append(val_acc)\n",
    "    fold_train_loss.append(avg_train_loss)\n",
    "    fold_val_loss.append(avg_val_loss)\n",
    "\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        save_path = \"./Modelos/v2/representacion_1/longitud_8\"\n",
    "        os.makedirs(save_path, exist_ok=True)\n",
    "        torch.save(model.state_dict(), f\"{save_path}/CNN1D_fold_{fold+1}.pth\")\n",
    "        best_epoch_train_acc = epoch_train_acc.copy()\n",
    "        best_epoch_val_acc = epoch_val_acc.copy()\n",
    "        best_epoch_train_loss = epoch_train_loss.copy()\n",
    "        best_epoch_val_loss = epoch_val_loss.copy()\n",
    "\n",
    "print(\"\\nRESULTADOS:\")\n",
    "print(f\"-> Mean Train Accuracy: {np.mean(fold_train_acc):.4f}%\")\n",
    "print(f\"-> Mean Train Loss: {np.mean(fold_train_loss):.4f}\")\n",
    "print(f\"-> Mean Validation Accuracy: {np.mean(fold_val_acc):.4f}%\")\n",
    "print(f\"-> Mean Validation Loss: {np.mean(fold_val_loss):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Graficar los resultados del entrenamiento :***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(1, num_epochs + 1), best_epoch_train_acc, label=\"Train Accuracy\")\n",
    "plt.plot(range(1, num_epochs + 1), best_epoch_val_acc, label=\"Validation Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy (%)\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(1, num_epochs + 1), best_epoch_train_loss, label=\"Train Loss\")\n",
    "plt.plot(range(1, num_epochs + 1), best_epoch_val_loss, label=\"Validation Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'./Graficas_entrenamiento/representacion_1/longitud_8/CNN1D.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Cargar el modelo :***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(\"./Modelos/v2/representacion_1/longitud_8/CNN1D_fold_5.pth\"))\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Evaluar el modelo :***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Matriz de confusi√≥n :***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['Cargo', 'Container','Tanker']\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
    "disp.plot(cmap=\"Blues\", xticks_rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***An√°lisis de los resultados obtenidos :***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(all_labels, all_preds, target_names=class_names))\n",
    "\n",
    "output_dir = Path('./Resultados/v2/representacion_1/longitud_8')\n",
    "\n",
    "classification_text = classification_report(all_labels, all_preds, target_names=class_names)\n",
    "\n",
    "with open(output_dir / 'CNN1D_report.txt', 'w') as f:\n",
    "    f.write(classification_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
