{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Importamos las librerías necesarias :***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder, OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Guardamos las trayectorias con sus respectivas clases en \"complete_df\" :***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: Cargo, Bearing: [96.5905, 78.9129, 107.9285, 79.5855, 101.9231, 69.7462, 95.8744]\n",
      "Type: Container, Bearing: [89.3541, 89.7018, 89.6913, 89.5125, 89.7389, 89.62, 89.7405]\n",
      "Type: Cruise, Bearing: [88.8022, 98.1133, 88.558, 84.8833, 93.6194, 78.3894, 93.7414]\n",
      "Type: Fishing, Bearing: [233.7547, 89.9999, 261.005, 308.6651, 247.3507, 186.4404, 148.1713]\n",
      "Type: Tanker, Bearing: [93.0646, 93.4023, 91.6164, 82.2953, 81.0646, 83.0176, 87.048]\n",
      "\n",
      "Número total de trayectorias: 14486\n",
      "Type\n",
      "Fishing      2927\n",
      "Cargo        2919\n",
      "Tanker       2892\n",
      "Container    2886\n",
      "Cruise       2862\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "csv_files = [\n",
    "    \"./Trayectorias/Tipos_de_barcos/Cargo_modificado_compressed.csv\",\n",
    "    \"./Trayectorias/Tipos_de_barcos/Container_modificado_compressed.csv\",\n",
    "    \"./Trayectorias/Tipos_de_barcos/Cruise_modificado_compressed.csv\",\n",
    "    \"./Trayectorias/Tipos_de_barcos/Fishing_modificado_compressed.csv\",\n",
    "    \"./Trayectorias/Tipos_de_barcos/Tanker_modificado_compressed.csv\"\n",
    "]\n",
    "\n",
    "complete_df = pd.DataFrame()\n",
    "\n",
    "for file in csv_files:\n",
    "    df = pd.read_csv(file)\n",
    "    df['Bearing'] = df['Bearing'].round(4)\n",
    "    grouped = df.groupby('Trajectory_ID')['Bearing'].apply(lambda x: [i for i in x if pd.notna(i)]).reset_index()\n",
    "    grouped['Type'] = file.split('/')[-1].split('_')[0]\n",
    "    complete_df = pd.concat([complete_df, grouped], ignore_index=True)\n",
    "\n",
    "### COMPROBACIÓN BEARING ###\n",
    "for tipo in complete_df['Type'].unique():\n",
    "    first_element = complete_df[complete_df['Type'] == tipo].iloc[0]\n",
    "    print(f\"Type: {tipo}, Bearing: {first_element['Bearing']}\")\n",
    "\n",
    "print()\n",
    "\n",
    "### COMPROBACIÓN NÚMERO DE TRAYECTORIAS ###\n",
    "print(\"Número total de trayectorias:\", len(complete_df))\n",
    "class_counts = complete_df['Type'].value_counts()\n",
    "print(class_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Dividimos \"complete_df\" en entrenamiento y test :***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nº de trayectorias en train: 11591\n",
      "Type\n",
      "Fishing      2342\n",
      "Cargo        2336\n",
      "Tanker       2314\n",
      "Container    2309\n",
      "Cruise       2290\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Nº de trayectorias en test: 2895\n",
      "Type\n",
      "Fishing      585\n",
      "Cargo        583\n",
      "Tanker       578\n",
      "Container    577\n",
      "Cruise       572\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Ejm. conjunto train:\n",
      "   Trajectory_ID                                            Bearing       Type\n",
      "0           4465  [110.934, 83.0412, 136.7822, 101.2178, 64.1802...      Cargo\n",
      "1          14619  [271.1761, 13.8253, 277.0206, 67.833, 199.7051...  Container\n",
      "2          13151  [89.6625, 89.7794, 89.6551, 89.8846, 89.6753, ...    Fishing\n",
      "3           9758  [81.925, 100.7672, 82.8752, 104.7483, 73.4801,...     Tanker\n",
      "4          15204  [79.8872, 83.1972, 83.8323, 33.9177, 59.6246, ...      Cargo\n",
      "\n",
      "Ejm. conjunto test:\n",
      "   Trajectory_ID                                            Bearing       Type\n",
      "0           1981  [89.9999, 68.5169, 135.0583, 48.6043, 98.4034,...    Fishing\n",
      "1           6712  [76.9442, 111.9344, 167.1519, 98.0953, 61.8368...  Container\n",
      "2           8458  [89.76, 89.7231, 89.7231, 89.8016, 89.692, 89....     Cruise\n",
      "3           6653  [89.7347, 89.7324, 89.8634, 89.6063, 89.7405, ...      Cargo\n",
      "4           5934  [80.9159, 132.9734, 84.2732, 104.7769, 129.565...     Cruise\n"
     ]
    }
   ],
   "source": [
    "complete_df = complete_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "test_size = 0.2\n",
    "train_df_list = []\n",
    "test_df_list = []\n",
    "\n",
    "classes = complete_df['Type'].unique()\n",
    "\n",
    "for class_name in classes:\n",
    "    class_subset = complete_df[complete_df['Type'] == class_name]\n",
    "    \n",
    "    test_count = int(len(class_subset) * test_size)\n",
    "    \n",
    "    test_df_list.append(class_subset.iloc[:test_count])\n",
    "    train_df_list.append(class_subset.iloc[test_count:])\n",
    "\n",
    "train_df = pd.concat(train_df_list).reset_index(drop=True)\n",
    "test_df = pd.concat(test_df_list).reset_index(drop=True)\n",
    "\n",
    "train_df = train_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "test_df = test_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "#### COMPROBACIÓN ####\n",
    "print(f\"Nº de trayectorias en train: {len(train_df)}\")\n",
    "print(train_df['Type'].value_counts())\n",
    "print()\n",
    "print(f\"Nº de trayectorias en test: {len(test_df)}\")\n",
    "print(test_df['Type'].value_counts())\n",
    "print()\n",
    "print(\"Ejm. conjunto train:\")\n",
    "print(train_df.head(5))\n",
    "print()\n",
    "print(\"Ejm. conjunto test:\")\n",
    "print(test_df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Pre-procesado de los datos :***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (11591, 7, 1)\n",
      "y_train: (11591, 5)\n",
      "X_test: (2895, 7, 1)\n",
      "y_test: (2895, 5)\n"
     ]
    }
   ],
   "source": [
    "#Convertimos Bearing a un array de numpy\n",
    "X_train = np.array(train_df['Bearing'].tolist())\n",
    "X_test = np.array(test_df['Bearing'].tolist())\n",
    "\n",
    "#Normalizamos los valores de Bearing\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "#Añadimos una dimensión extra para que tenga la forma (n, 1)\n",
    "X_train = np.expand_dims(X_train, axis = -1)\n",
    "X_test = np.expand_dims(X_test, axis = -1)\n",
    "\n",
    "#Codificamos las etiquetas de Type\n",
    "label_encoder = LabelEncoder()\n",
    "y_train = label_encoder.fit_transform(train_df['Type'])\n",
    "y_test = label_encoder.transform(test_df['Type'])\n",
    "\n",
    "#Convertimos las etiquetas a one-hot encoding\n",
    "encoder = OneHotEncoder(sparse_output=False, categories='auto')\n",
    "y_train = encoder.fit_transform(np.array(y_train).reshape(-1, 1))\n",
    "y_test = encoder.transform(np.array(y_test).reshape(-1, 1))\n",
    "\n",
    "#### COMPROBACIÓN ####\n",
    "print(\"X_train:\", X_train.shape)\n",
    "print(\"y_train:\", y_train.shape)\n",
    "print(\"X_test:\", X_test.shape)\n",
    "print(\"y_test:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Conversión a tensores :***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "X_train_tensor: torch.Size([11591, 7, 1]) cuda:0\n",
      "y_train_tensor: torch.Size([11591, 5]) cuda:0\n",
      "X_test_tensor: torch.Size([2895, 7, 1]) cuda:0\n",
      "y_test_tensor: torch.Size([2895, 5]) cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).to(device)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to(device)\n",
    "\n",
    "print(\"X_train_tensor:\", X_train_tensor.shape, X_train_tensor.device)\n",
    "print(\"y_train_tensor:\", y_train_tensor.shape, y_train_tensor.device)\n",
    "print(\"X_test_tensor:\", X_test_tensor.shape, X_test_tensor.device)\n",
    "print(\"y_test_tensor:\", y_test_tensor.shape, y_test_tensor.device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
