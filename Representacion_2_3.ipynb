{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Importamos las librerías necesarias :***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "from io import BytesIO\n",
    "from pathlib import Path\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.models import alexnet, AlexNet_Weights\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from torchvision.models import densenet121, DenseNet121_Weights\n",
    "from torchvision.models import convnext_tiny, ConvNeXt_Tiny_Weights\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset, Subset\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score, classification_report, roc_curve, auc, roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Guardamos las imágenes con sus respectivas clases en \"complete_df\" :***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = Path('./Imagenes/Trayectorias_dominio_tiempo_frecuencia/longitud_28/raw-img-anomalias-v1')\n",
    "\n",
    "file_paths = list(image_dir.rglob(\"*.jpg\")) + \\\n",
    "             list(image_dir.rglob(\"*.jpeg\")) + \\\n",
    "             list(image_dir.rglob(\"*.png\"))\n",
    "\n",
    "complete_df = pd.DataFrame()\n",
    "complete_df['file_name'] = [str(p) for p in file_paths]\n",
    "complete_df['class_name'] = complete_df['file_name'].map(lambda x: Path(x).parent.name)\n",
    "\n",
    "### COMPROBACIÓN ###\n",
    "print(\"Número total de imágenes:\", len(complete_df))\n",
    "class_counts = complete_df['class_name'].value_counts()\n",
    "print(class_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Dividimos \"complete_df\" en entrenamiento y test :***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_df = complete_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "test_size = 0.2\n",
    "train_df_list = []\n",
    "test_df_list = []\n",
    "\n",
    "classes = complete_df['class_name'].unique()\n",
    "\n",
    "for class_name in classes:\n",
    "    class_subset = complete_df[complete_df['class_name'] == class_name]\n",
    "    \n",
    "    test_count = int(len(class_subset) * test_size)\n",
    "    \n",
    "    test_df_list.append(class_subset.iloc[:test_count])\n",
    "    train_df_list.append(class_subset.iloc[test_count:])\n",
    "\n",
    "train_df = pd.concat(train_df_list).reset_index(drop=True)\n",
    "test_df = pd.concat(test_df_list).reset_index(drop=True)\n",
    "\n",
    "train_df = train_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "test_df = test_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "#### COMPROBACIÓN ####\n",
    "print(f\"Nº de imágenes en train: {len(train_df)}\")\n",
    "print(train_df['class_name'].value_counts())\n",
    "print()\n",
    "print(f\"Nº de imágenes en test: {len(test_df)}\")\n",
    "print(test_df['class_name'].value_counts())\n",
    "print()\n",
    "print(\"Ejm. conjunto train:\")\n",
    "print(train_df.head(10))\n",
    "print()\n",
    "print(\"Ejm. conjunto test:\")\n",
    "print(test_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Imágenes de entrenamiento y test antes del pre-procesado :***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mostrar_imagenes_antes_preprocesado(df):\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    grouped = df.groupby('class_name')\n",
    "    \n",
    "    for i, (class_name, group) in enumerate(grouped):\n",
    "        image_path = group['file_name'].iloc[0]\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        \n",
    "        plt.subplot(1, len(grouped), i + 1)\n",
    "        plt.imshow(image)\n",
    "        plt.title(class_name)\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "mostrar_imagenes_antes_preprocesado(train_df)\n",
    "mostrar_imagenes_antes_preprocesado(test_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Pre-procesado de las imágenes :***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = (227, 227)\n",
    "X_train = []\n",
    "y_train = []\n",
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"{device} disponible\")\n",
    "\n",
    "transform = transforms.Compose([transforms.Resize(IMG_SIZE),transforms.ToTensor()])\n",
    "\n",
    "def preprocesado_imagen(image_path):\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    image = transform(image)\n",
    "    return image\n",
    "\n",
    "for index, row in train_df.iterrows():\n",
    "    image_tensor = preprocesado_imagen(row['file_name'])\n",
    "    X_train.append(image_tensor)\n",
    "    y_train.append(row['class_name'])\n",
    "\n",
    "for index, row in test_df.iterrows():\n",
    "    image_tensor = preprocesado_imagen(row['file_name'])\n",
    "    X_test.append(image_tensor)\n",
    "    y_test.append(row['class_name'])\n",
    "\n",
    "X_train = torch.stack(X_train)\n",
    "X_test = torch.stack(X_test)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "y_train = torch.tensor(y_train_encoded, dtype=torch.long)\n",
    "y_test = torch.tensor(y_test_encoded, dtype=torch.long)\n",
    "\n",
    "### COMPROBACIÓN ###\n",
    "print(\"X_train:\", X_train.shape, X_train.device)\n",
    "print(\"y_train:\", y_train.shape, y_train.device)\n",
    "print(\"X_test:\", X_test.shape, X_test.device)\n",
    "print(\"y_test:\", y_test.shape, y_test.device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***AlexNet :***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_alexnet_model(num_classes, pretrained):\n",
    "    if pretrained:\n",
    "        modelo = alexnet(weights=AlexNet_Weights.DEFAULT)\n",
    "    else:\n",
    "        modelo = alexnet(weights=None)\n",
    "\n",
    "    modelo.classifier[6] = nn.Linear(modelo.classifier[6].in_features, num_classes)\n",
    "\n",
    "    if pretrained:\n",
    "        for param in modelo.features.parameters():\n",
    "            param.requires_grad = False\n",
    "            \n",
    "        for param in modelo.classifier[6].parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "    return modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***ResNet50 :***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_resnet50_model(num_classes, pretrained):\n",
    "    if pretrained:\n",
    "        modelo = resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "    else:\n",
    "        modelo = resnet50(weights=None)\n",
    "\n",
    "    modelo.fc = nn.Linear(modelo.fc.in_features, num_classes)\n",
    "\n",
    "    if pretrained:\n",
    "        for param in modelo.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        for param in modelo.fc.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "    return modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***DenseNet121 :***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_densenet121_model(num_classes, pretrained):\n",
    "    if pretrained:\n",
    "        modelo = densenet121(weights=DenseNet121_Weights.DEFAULT)\n",
    "    else:\n",
    "        modelo = densenet121(weights=None)\n",
    "\n",
    "    modelo.classifier = nn.Linear(modelo.classifier.in_features, num_classes)\n",
    "\n",
    "    if pretrained:\n",
    "        for param in modelo.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        for param in modelo.classifier.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "    return modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***ConvNeXt Tiny :***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_convnext_tiny_model(num_classes, pretrained):\n",
    "    if pretrained:\n",
    "        modelo = convnext_tiny(weights=ConvNeXt_Tiny_Weights.DEFAULT)\n",
    "    else:\n",
    "        modelo = convnext_tiny(weights=None)\n",
    "\n",
    "    modelo.classifier[2] = nn.Linear(modelo.classifier[2].in_features, num_classes)\n",
    "\n",
    "    if pretrained:\n",
    "        for param in modelo.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        for param in modelo.classifier[2].parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "    return modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Configuración del modelo :***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_folds = 2\n",
    "batch_size = 32\n",
    "num_epochs = 100\n",
    "num_classes = 2\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Entrenamiento del modelo :***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "kfold = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "\n",
    "fold_train_acc = []\n",
    "fold_train_loss = []\n",
    "fold_val_acc = []\n",
    "fold_val_loss = []\n",
    "\n",
    "best_val_acc = 0\n",
    "best_epoch_train_acc = []\n",
    "best_epoch_val_acc = []\n",
    "best_epoch_train_loss = []\n",
    "best_epoch_val_loss = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kfold.split(train_dataset)):\n",
    "\n",
    "    epoch_train_acc = []\n",
    "    epoch_val_acc = []\n",
    "    epoch_train_loss = []\n",
    "    epoch_val_loss = []\n",
    "\n",
    "    print(f\"\\n📂 Fold {fold+1}/{k_folds}\")\n",
    "\n",
    "    train_subset = Subset(train_dataset, train_idx)\n",
    "    val_subset = Subset(train_dataset, val_idx)\n",
    "\n",
    "    train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True, num_workers=16, pin_memory=True)\n",
    "    val_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=False, num_workers=16, pin_memory=True)\n",
    "\n",
    "    #nombre_modelo = \"AlexNet\"\n",
    "    #modelo = get_alexnet_model(num_classes=num_classes, pretrained=False).to(device)\n",
    "    \n",
    "    #nombre_modelo = \"ResNet50\"\n",
    "    #modelo = get_resnet50_model(num_classes=num_classes, pretrained=True).to(device)\n",
    "    \n",
    "    #nombre_modelo = \"DenseNet121\"\n",
    "    #modelo = get_densenet121_model(num_classes=num_classes, pretrained=True).to(device)\n",
    "    \n",
    "    nombre_modelo = \"ConvNext_Tiny\"\n",
    "    modelo = get_convnext_tiny_model(num_classes=num_classes, pretrained=True).to(device)\n",
    "\n",
    "    #Pesos inversamente proporcionales a la frecuencia de las clases\n",
    "    label_counts = Counter(y_train.cpu().numpy())\n",
    "    total_count = sum(label_counts.values())\n",
    "    weights = [total_count / (num_classes * label_counts[label]) for label in range(len(label_counts))]\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss(weight=torch.tensor(weights).to(device))\n",
    "    optimizer = optim.Adam(filter(lambda p: p.requires_grad, modelo.parameters()), lr=0.001)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        modelo.train()\n",
    "        train_loss = 0\n",
    "        correct_train = 0\n",
    "        total_train = 0\n",
    "\n",
    "        for images, labels in tqdm(train_loader, desc=f\"Fold {fold+1} | Epoch {epoch+1}/{num_epochs}\"):\n",
    "            images, labels = images.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
    "            optimizer.zero_grad()\n",
    "            output = modelo(images)\n",
    "            loss = criterion(output, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            _, predicted = torch.max(output, 1)\n",
    "            correct_train += (predicted == labels).sum().item()\n",
    "            total_train += labels.size(0)\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        train_acc = 100 * correct_train / total_train\n",
    "\n",
    "        modelo.eval()\n",
    "        val_loss = 0\n",
    "        correct_val = 0\n",
    "        total_val = 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
    "                output = modelo(images)\n",
    "                loss = criterion(output, labels)\n",
    "                _, predicted = torch.max(output, 1)\n",
    "                correct_val += (predicted == labels).sum().item()\n",
    "                total_val += labels.size(0)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        val_acc = 100 * correct_val / total_val\n",
    "\n",
    "        epoch_train_acc.append(train_acc)\n",
    "        epoch_val_acc.append(val_acc)\n",
    "        epoch_train_loss.append(avg_train_loss)\n",
    "        epoch_val_loss.append(avg_val_loss)\n",
    "\n",
    "        print(f\"Fold {fold+1} - Epoch {epoch+1} ✅ | Train Acc: {train_acc:.2f}% - Train Loss: {avg_train_loss:.4f} | Val Acc: {val_acc:.2f}% - Val Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "    fold_train_acc.append(train_acc)\n",
    "    fold_val_acc.append(val_acc)\n",
    "    fold_train_loss.append(avg_train_loss)\n",
    "    fold_val_loss.append(avg_val_loss)\n",
    "\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        save_path = \"./Modelos/anomalias-v1/representacion_3/longitud_28\"\n",
    "        os.makedirs(save_path, exist_ok=True)\n",
    "        torch.save(modelo.state_dict(), f\"{save_path}/{nombre_modelo}_fold_{fold+1}.pth\")\n",
    "        best_epoch_train_acc = epoch_train_acc.copy()\n",
    "        best_epoch_val_acc = epoch_val_acc.copy()\n",
    "        best_epoch_train_loss = epoch_train_loss.copy()\n",
    "        best_epoch_val_loss = epoch_val_loss.copy()\n",
    "\n",
    "print(\"\\nRESULTADOS:\")\n",
    "print(f\"-> Mean Train Accuracy: {np.mean(fold_train_acc):.4f}%\")\n",
    "print(f\"-> Mean Train Loss: {np.mean(fold_train_loss):.4f}\")\n",
    "print(f\"-> Mean Validation Accuracy: {np.mean(fold_val_acc):.4f}%\")\n",
    "print(f\"-> Mean Validation Loss: {np.mean(fold_val_loss):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Graficar los resultados del entrenamiento :***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(1, num_epochs + 1), best_epoch_train_acc, label=\"Train Accuracy\")\n",
    "plt.plot(range(1, num_epochs + 1), best_epoch_val_acc, label=\"Validation Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy (%)\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(1, num_epochs + 1), best_epoch_train_loss, label=\"Train Loss\")\n",
    "plt.plot(range(1, num_epochs + 1), best_epoch_val_loss, label=\"Validation Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'./Graficas_entrenamiento/anomalias-v1/representacion_3/longitud_28/{nombre_modelo}.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Cargar el modelo :***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modelo = get_densenet121_model(num_classes=num_classes, pretrained=True).to(device)\n",
    "\n",
    "modelo.load_state_dict(torch.load(\"./Modelos/anomalias-v1/representacion_3/longitud_28/ConvNext_Tiny_fold_2.pth\"))\n",
    "modelo.to(device)\n",
    "modelo.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Evaluar el modelo :***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds = []\n",
    "all_labels = []\n",
    "all_probs = []\n",
    "\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=16, pin_memory=True)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = modelo(images)\n",
    "        #_, predicted = torch.max(outputs, 1)\n",
    "        probs = torch.softmax(outputs, dim=1)[:,1]\n",
    "        predicted = torch.argmax(outputs, dim=1)\n",
    "\n",
    "        all_probs.extend(probs.cpu().numpy())\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Matriz de confusión :***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#class_names = ['AIS(30)','AIS(31-32)','AIS(36)','AIS(37)','AIS(52)','AIS(56-57)','AIS(60-69)','AIS(70-79)','AIS(80-89)','AIS(90-99)']\n",
    "#class_names = ['Cargo', 'Fishing', 'Military', 'Sailing', 'Tanker']\n",
    "#class_names = ['Cargo','Container','Cruise','Fishing','Tanker']\n",
    "#class_names = ['Cargo', 'Container','Tanker']\n",
    "class_names = ['0', '1']\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
    "disp.plot(cmap=\"Blues\", xticks_rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(all_labels, all_probs)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'Curva ROC (AUC = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Tasa de Falsos Positivos (FPR)')\n",
    "plt.ylabel('Tasa de Verdaderos Positivos (TPR)')\n",
    "plt.title('Curva ROC')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# 🔢 AUC como número\n",
    "print(f\"AUC: {roc_auc_score(all_labels, all_probs):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Análisis de los resultados obtenidos :***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(all_labels, all_preds, target_names=class_names))\n",
    "\n",
    "output_dir = Path('./Resultados/anomalias-v1/representacion_3/longitud_28')\n",
    "\n",
    "classification_text = classification_report(all_labels, all_preds, target_names=class_names)\n",
    "\n",
    "with open(output_dir / 'ConvNext_Tiny_report.txt', 'w') as f:\n",
    "    f.write(classification_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
